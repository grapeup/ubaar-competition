{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "competitive-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import IPython.display as ipd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thick-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('..', 'data', 'processed', 'ubaar_features.csv'), encoding=\"utf-8\", index_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pretty-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49371, 52)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "figured-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = data.columns\n",
    "# features_columns = [c for c in features_columns if not c.startswith('cluster_')]\n",
    "features_columns = [c for c in features_columns if not c.startswith('weight_d')]\n",
    "features_columns = list(features_columns)\n",
    "features_columns.remove('price')\n",
    "features_columns = np.array(features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "soviet-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_columns = data.columns[data.columns  != 'price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atmospheric-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mlflow():\n",
    "    remote_server_uri = \"http://18.185.244.61:5050\"\n",
    "    mlflow.set_tracking_uri(remote_server_uri)\n",
    "    mlflow.set_experiment(\"UbaarCV\") \n",
    "    mlflow.end_run()\n",
    "    mlflow.start_run(run_name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "thrown-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sklearn(x_train, y_train, x_dev, y_dev):\n",
    "#     model = Ridge(alpha=5.0, fit_intercept=True, normalize=False, copy_X=True, solver='auto', random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=20, max_depth=20, min_samples_leaf=8, random_state=42)\n",
    "    \n",
    "    \n",
    "    model.fit(x_train, np.log(y_train * 0.95))\n",
    "\n",
    "    preds_train = np.exp(model.predict(x_train))\n",
    "    preds_dev = np.exp(model.predict(x_dev))\n",
    "\n",
    "    return preds_train, preds_dev, model.__dict__\n",
    "\n",
    "PARAMS = {'objective': 'reg:squarederror',\n",
    "          'eval_metric': 'mape',\n",
    "         'booster': 'gbtree', 'eta': 0.05, 'max_depth': 16,\n",
    "         'min_child_weight': 0.01,\n",
    "         'subsample': 0.95, 'colsample_bytree': 0.7,\n",
    "         'colsample_bylevel': 0.06, 'alpha': 0.0,\n",
    "         'lambda': 0.5, 'seed': 42, 'gamma': 0.0,\n",
    "         'max_delta_step': 0, 'nthred': 4,\n",
    "         'min_split_gain': 0.0, 'early_stopping_rounds': 300}\n",
    "\n",
    "def train_xgb(x_train, y_train, x_dev, y_dev):\n",
    "    \n",
    "    dtrain = xgb.DMatrix(x_train, label=np.log(y_train * 0.95))\n",
    "    dtest = xgb.DMatrix(x_dev, label=np.log(y_dev * 0.95))\n",
    "    evallist = [(dtest, 'eval')]\n",
    "    \n",
    "    model = xgb.train(PARAMS, dtrain, 3000, evals=evallist, verbose_eval=False)\n",
    "    preds_train = np.exp(model.predict(dtrain, model.best_iteration+0))\n",
    "    preds_dev = np.exp(model.predict(dtest, model.best_iteration+0))\n",
    "#     print(model.best_iteration)\n",
    "    model_params = PARAMS\n",
    "    return preds_train, preds_dev, model_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "magnetic-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, min_split_gain, nthred } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train MAPE: 0.05001071237189561\n",
      "Dev MAPE: 0.1647930244056891\n",
      "[16:01:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, min_split_gain, nthred } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train MAPE: 0.04999155077654669\n",
      "Dev MAPE: 0.16590442404350966\n",
      "[16:02:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, min_split_gain, nthred } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train MAPE: 0.049997700578523485\n",
      "Dev MAPE: 0.16474444786197445\n",
      "[16:03:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, min_split_gain, nthred } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train MAPE: 0.04999789533328018\n",
      "Dev MAPE: 0.16270523231119177\n",
      "[16:04:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, min_split_gain, nthred } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Train MAPE: 0.050005882496312444\n",
      "Dev MAPE: 0.1665751789404133\n",
      "================\n",
      "Mean MAPE: 0.16494446151255565\n",
      "Std MAPE: 0.0013158915961696783\n"
     ]
    }
   ],
   "source": [
    "setup_mlflow()\n",
    "mlflow.log_param('features', features_columns)\n",
    "\n",
    "\n",
    "y_full = data['price'].values\n",
    "x_full = data[features_columns].values\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_mapes = []\n",
    "dev_mapes = []\n",
    "dev_preds = []\n",
    "dev_refs = []\n",
    "dev_inds = []\n",
    "\n",
    "for train_ind, dev_ind in kfold.split(x_full):\n",
    "    \n",
    "    x_train = x_full[train_ind]\n",
    "    y_train = y_full[train_ind]\n",
    "    x_dev = x_full[dev_ind]\n",
    "    y_dev = y_full[dev_ind]\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(x_train)\n",
    "#     x_train = scaler.transform(x_train)\n",
    "#     x_dev = scaler.transform(x_dev)\n",
    "\n",
    "#     preds_train, preds_dev, model_params = train_sklearn(x_train, y_train, x_dev, y_dev)\n",
    "    preds_train, preds_dev, model_params = train_xgb(x_train, y_train, x_dev, y_dev)\n",
    "#     preds_train2, preds_dev2, model_params2 = train_xgb(x_train, y_train, x_dev, y_dev)\n",
    "    \n",
    "#     preds_train = (preds_train + preds_train2)/2\n",
    "#     preds_dev = (preds_dev + preds_dev2)/2\n",
    "    \n",
    "    mlflow.log_param('features', features_columns)\n",
    "    mlflow.log_param('model_params', model_params)\n",
    "\n",
    "    train_mape = mean_absolute_percentage_error(y_train, preds_train)\n",
    "    dev_mape = mean_absolute_percentage_error(y_dev, preds_dev)\n",
    "    \n",
    "    train_mapes.append(train_mape)\n",
    "    dev_mapes.append(dev_mape)\n",
    "    \n",
    "    dev_preds.extend(list(preds_dev))\n",
    "    dev_refs.extend(list(y_dev))\n",
    "    dev_inds.extend(list(dev_ind))\n",
    "    \n",
    "    print(f\"Train MAPE: {train_mape}\")\n",
    "    print(f\"Dev MAPE: {dev_mape}\")\n",
    "#     break\n",
    "# \n",
    "print(\"================\")\n",
    "print(f\"Mean MAPE: {np.mean(dev_mapes)}\")\n",
    "print(f\"Std MAPE: {np.std(dev_mapes)}\")\n",
    "\n",
    "mlflow.log_metric(\"Mean dev MAPE\", np.mean(dev_mapes))\n",
    "mlflow.log_metric(\"Std dev MAPE\", np.std(dev_mapes))\n",
    "                  \n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(list(zip(dev_refs, dev_preds, dev_inds)), columns=['refs', 'preds', 'inds'])\n",
    "results = results.sort_values('inds')\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = model.feature_importances_.argsort()\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.barh(features_columns[sorted_idx], model.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Random Forest Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-singer",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-jackson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-granny",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
